
robots.txt란?

- robots.txt는 로봇 배제 표준으로 알려진 규약으로서 해당 웹사이트에 대한 크롤링 지침을 전달하기 위한 용도로 사용된다. 
쉽게 말해 접근 가능/불가능한 페이지, 디렉터리, 크롤러를 명시함으로써 크롤러를 제어할 수 있는 파일이다.

- 악의적 목적을 가진 해커가 robots.txt 파일에 접근하여 특정 페이지가 Disallow로 설정 된 것을 확인한다면,
페이지에 흥미로운 정보가 있다고 추측하여 해당 페이지에 접근하여 민감한 정보를 획득하려고 할 것이다.

http://<ip-address>/robots.txt

User-agent: *
Disallow: /whatever
Disallow: /.hidden

http://<ip-address>/whatever
htpaswd 파일
인증할 사용자의 ID와 패스워드리스트를 보관하고 있는 파일이며, 
해당 페이지로 접근하려할 때 인증창이 뜬 후에 이 파일에 있는 ID와 패스워드를 맞게 입력하면 접속을 허용하게되고, 그렇지 않으면 접속허용을 하지않게 됩니다.
주로 관리자 페이지를 접근할 수 있는 아이디와 패스워드를 담고 있다.

location /admin {
        auth_basic "Admin page";
        auth_basic_user_file /etc/nginx/.htpasswd;
    }

root:8621ffdbc5698829397d97767ac13db3

8621ffdbc5698829397d97767ac13db3 in md5 => dragon

http://<ip-address>/admin
root/dragon으로 로그인 =>
The flag is : d19b4823e0d5600ceed56d5e896ef328d7a2b9e7ac7e80f4fcdb9b10bcb3e7ff

대응방법
1. htpasswd가 들어있는 디렉터리로 직접 접근하지 못 하게 권한을 설정한다.
2. 웹 사이트 디렉터리에 절대로 중요 정보를 저장하지 않는다.